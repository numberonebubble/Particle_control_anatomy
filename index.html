<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Bio-Interactive Particle Heart</title>
    <style>
        body { margin: 0; overflow: hidden; background-color: #050505; font-family: 'Segoe UI', sans-serif; }
        
        /* Three.js Container */
        #canvas-container { position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 1; }

        /* UI Overlay - Heart Rate */
        #ui-layer {
            position: absolute; top: 20px; right: 20px; z-index: 10;
            color: white; text-align: right;
            background: rgba(0, 0, 0, 0.5); padding: 15px; border-radius: 12px;
            backdrop-filter: blur(5px); border: 1px solid rgba(255, 255, 255, 0.1);
        }
        .bpm-label { font-size: 12px; text-transform: uppercase; letter-spacing: 2px; color: #aaa; }
        .bpm-value { font-size: 48px; font-weight: 700; color: #ff3366; text-shadow: 0 0 20px rgba(255, 51, 102, 0.6); }
        .status { font-size: 10px; color: #666; margin-top: 5px; }

        /* Webcam Feed - Bottom Right */
        #cam-container {
            position: absolute; bottom: 20px; right: 20px; z-index: 10;
            width: 240px; height: 180px;
            border-radius: 12px; overflow: hidden;
            border: 2px solid rgba(255, 255, 255, 0.1);
            background: #000;
        }
        #input-video {
            position: absolute; width: 100%; height: 100%; object-fit: cover;
            transform: scaleX(-1); /* Mirror effect */
        }
        #overlay-canvas {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            transform: scaleX(-1);
        }

        /* Loading Spinner */
        #loader {
            position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%);
            color: white; z-index: 20; font-size: 24px; pointer-events: none;
        }
    </style>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
</head>
<body>

    <div id="loader">Initializing AI Models...</div>

    <div id="ui-layer">
        <div class="bpm-label">Heart Rate</div>
        <div class="bpm-value" id="bpm-display">--</div>
        <div class="status" id="ppg-status">Acquiring signal...</div>
    </div>

    <div id="cam-container">
        <video id="input-video" playsinline></video>
        <canvas id="overlay-canvas"></canvas>
    </div>

    <div id="canvas-container"></div>

<script>
/**
 * PART 1: THREE.JS PARTICLE SYSTEM
 */
const scene = new THREE.Scene();
scene.fog = new THREE.FogExp2(0x050505, 0.002);

const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
camera.position.z = 30;

const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
renderer.setSize(window.innerWidth, window.innerHeight);
document.getElementById('canvas-container').appendChild(renderer.domElement);

// Particle Configuration
const particleCount = 15000;
const geometry = new THREE.BufferGeometry();
const positions = new Float32Array(particleCount * 3);
const colors = new Float32Array(particleCount * 3);
const targetPositions = new Float32Array(particleCount * 3); // Heart shape
const randomPositions = new Float32Array(particleCount * 3); // Exploded shape

const color1 = new THREE.Color(0xff3366); // Heart Red
const color2 = new THREE.Color(0x44aaff); // Sci-fi Blue

// Initialize Particles
for (let i = 0; i < particleCount; i++) {
    // 1. Create Heart Shape (Parametric Equations)
    // x = 16sin^3(t)
    // y = 13cos(t) - 5cos(2t) - 2cos(3t) - cos(4t)
    const t = Math.random() * Math.PI * 2;
    const u = Math.random() * Math.PI * 2; // For volume
    
    // Basic heart curve
    let x = 16 * Math.pow(Math.sin(t), 3);
    let y = 13 * Math.cos(t) - 5 * Math.cos(2 * t) - 2 * Math.cos(3 * t) - Math.cos(4 * t);
    let z = (Math.random() - 0.5) * 5; // Thin volume
    
    // Scale down to fit camera
    x *= 0.5; y *= 0.5; z *= 0.5;

    targetPositions[i * 3] = x;
    targetPositions[i * 3 + 1] = y;
    targetPositions[i * 3 + 2] = z;

    // 2. Create Random/Exploded State
    randomPositions[i * 3] = (Math.random() - 0.5) * 60;
    randomPositions[i * 3 + 1] = (Math.random() - 0.5) * 60;
    randomPositions[i * 3 + 2] = (Math.random() - 0.5) * 60;

    // Start at random
    positions[i * 3] = randomPositions[i * 3];
    positions[i * 3 + 1] = randomPositions[i * 3 + 1];
    positions[i * 3 + 2] = randomPositions[i * 3 + 2];

    colors[i * 3] = color2.r;
    colors[i * 3 + 1] = color2.g;
    colors[i * 3 + 2] = color2.b;
}

geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
geometry.setAttribute('color', new THREE.BufferAttribute(colors, 3));

const material = new THREE.PointsMaterial({
    size: 0.2,
    vertexColors: true,
    blending: THREE.AdditiveBlending,
    depthTest: false,
    transparent: true,
    opacity: 0.8
});

const particles = new THREE.Points(geometry, material);
scene.add(particles);

// State Variables
let handClosedAmount = 0; // 0 = Open (Exploded), 1 = Closed (Heart)
let currentBPM = 60;
let beatTime = 0;

/**
 * PART 2: COMPUTER VISION & LOGIC
 */
const videoElement = document.getElementById('input-video');
const canvasElement = document.getElementById('overlay-canvas');
const canvasCtx = canvasElement.getContext('2d');
const bpmDisplay = document.getElementById('bpm-display');
const ppgStatus = document.getElementById('ppg-status');

// PPG Variables
let foreheadGreenValues = [];
let lastBeatTime = 0;
const maxBuffer = 150; // Buffer for signal processing
let ppgCanvas; // Offscreen canvas to read pixels
let ppgCtx;

function setupPPG() {
    ppgCanvas = document.createElement('canvas');
    ppgCanvas.width = 100; // Low res is fine for color averaging
    ppgCanvas.height = 100;
    ppgCtx = ppgCanvas.getContext('2d');
}
setupPPG();

// --- Face Mesh for PPG ---
const faceMesh = new FaceMesh({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`});
faceMesh.setOptions({ maxNumFaces: 1, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });

faceMesh.onResults((results) => {
    if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
        const landmarks = results.multiFaceLandmarks[0];
        
        // Extract Forehead Region (approximate indices)
        // Mid-forehead is around index 10, 338, 297, 332
        const foreheadPoint = landmarks[151]; // Center forehead
        
        // Draw Overlay (Forehead dot)
        const x = foreheadPoint.x * canvasElement.width;
        const y = foreheadPoint.y * canvasElement.height;
        
        canvasCtx.fillStyle = '#00ff00';
        canvasCtx.beginPath();
        canvasCtx.arc(x, y, 3, 0, 2 * Math.PI);
        canvasCtx.fill();

        // --- PPG SIGNAL EXTRACTION ---
        // Crop a small area around the forehead from the video feed
        // Note: Video coordinates need mapping
        const vidW = videoElement.videoWidth;
        const vidH = videoElement.videoHeight;
        const cropX = Math.floor(foreheadPoint.x * vidW);
        const cropY = Math.floor(foreheadPoint.y * vidH);
        
        if (cropX > 0 && cropY > 0) {
            // Draw video frame to offscreen canvas
            ppgCtx.drawImage(videoElement, cropX - 10, cropY - 10, 20, 20, 0, 0, 20, 20);
            const frameData = ppgCtx.getImageData(0, 0, 20, 20);
            
            // Average Green Channel
            let avgGreen = 0;
            for (let i = 0; i < frameData.data.length; i += 4) {
                avgGreen += frameData.data[i + 1];
            }
            avgGreen /= (frameData.data.length / 4);

            processPPGSignal(avgGreen);
        }
    } else {
        ppgStatus.innerText = "Face not detected";
    }
});

// --- Simple Peak Detection for PPG ---
function processPPGSignal(value) {
    const now = performance.now();
    foreheadGreenValues.push({ val: value, time: now });
    if (foreheadGreenValues.length > maxBuffer) foreheadGreenValues.shift();

    if (foreheadGreenValues.length < 30) return; // Wait for buffer

    // Detrend: Calculate moving average
    let sum = 0;
    foreheadGreenValues.forEach(v => sum += v.val);
    const avg = sum / foreheadGreenValues.length;

    // Check for peak
    // A simplified algorithm: look for zero-crossing or local maxima above average
    const currentVal = foreheadGreenValues[foreheadGreenValues.length - 1].val;
    const prevVal = foreheadGreenValues[foreheadGreenValues.length - 2].val;
    const prevPrevVal = foreheadGreenValues[foreheadGreenValues.length - 3].val;

    // Peak detection logic
    // We are looking for a local maximum
    if (prevVal > currentVal && prevVal > prevPrevVal && prevVal > avg + 0.5) {
        // Potential beat
        const timeDiff = now - lastBeatTime;
        if (timeDiff > 400 && timeDiff < 1500) { // Limit to 40-150 BPM range
            const instantBPM = 60000 / timeDiff;
            // Smooth the BPM
            currentBPM = Math.round(currentBPM * 0.7 + instantBPM * 0.3);
            bpmDisplay.innerText = currentBPM;
            ppgStatus.innerText = "Signal Locked";
            
            // Trigger Visual Beat
            triggerHeartBeat();
        }
        lastBeatTime = now;
    }
}

function triggerHeartBeat() {
    beatTime = 1.0; // Reset beat animation scalar
}


// --- Hands for Gesture Control ---
const hands = new Hands({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
hands.setOptions({ maxNumHands: 2, minDetectionConfidence: 0.7, minTrackingConfidence: 0.5 });

hands.onResults((results) => {
    // Clear Overlay
    canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
    
    // Draw Hand Overlay
    if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        let totalClosedFactor = 0;

        for (const landmarks of results.multiHandLandmarks) {
            drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, {color: '#00FF00', lineWidth: 1});
            drawLandmarks(canvasCtx, landmarks, {color: '#FF0000', lineWidth: 0.5, radius: 2});

            // Calculate "Closedness"
            // Measure distance between Wrist (0) and Middle Finger Tip (12)
            const wrist = landmarks[0];
            const tip = landmarks[12];
            const base = landmarks[9]; // Middle finger MCP

            // Euclidian distance roughly
            const handSize = Math.hypot(base.x - wrist.x, base.y - wrist.y);
            const openDist = Math.hypot(tip.x - wrist.x, tip.y - wrist.y);
            
            // Ratio: If Tip is close to Wrist compared to palm size -> Closed
            // Normal open hand ratio ~ 1.8 to 2.0
            // Closed fist ratio ~ 0.8 to 1.0
            
            let ratio = openDist / handSize;
            // Map 1.8 -> 0 (Open), 1.0 -> 1 (Closed)
            let closed = (1.8 - ratio) / 0.8;
            closed = Math.max(0, Math.min(1, closed)); // Clamp
            
            totalClosedFactor += closed;
        }

        // Smooth transition
        const targetFactor = totalClosedFactor / results.multiHandLandmarks.length; // Average if 2 hands
        handClosedAmount += (targetFactor - handClosedAmount) * 0.1; // Lerp
    } else {
        // If no hands, slowly drift to open
        handClosedAmount += (0 - handClosedAmount) * 0.05;
    }
});

// --- Camera Setup ---
const cameraObj = new Camera(videoElement, {
    onFrame: async () => {
        await faceMesh.send({image: videoElement});
        await hands.send({image: videoElement});
    },
    width: 640,
    height: 480
});
cameraObj.start()
    .then(() => document.getElementById('loader').style.display = 'none')
    .catch(err => console.error("Camera Error:", err));


/**
 * PART 3: ANIMATION LOOP
 */
function animate() {
    requestAnimationFrame(animate);

    // Update Particles
    const positionsAttribute = geometry.attributes.position;
    const colorsAttribute = geometry.attributes.color;

    // Decay beat animation
    beatTime = Math.max(0, beatTime - 0.05);
    // Easing for beat: A quick expansion and slow contraction
    const beatScale = 1 + (Math.sin(beatTime * Math.PI) * 0.2 * handClosedAmount); // Beat only visible when heart forms

    const time = Date.now() * 0.001;
    scene.rotation.y = time * 0.1;

    for (let i = 0; i < particleCount; i++) {
        // Interpolate Positions based on Hand Gesture
        const rx = randomPositions[i * 3];
        const ry = randomPositions[i * 3 + 1];
        const rz = randomPositions[i * 3 + 2];

        // Target (Heart) with Beat Scaling applied
        const tx = targetPositions[i * 3] * beatScale;
        const ty = targetPositions[i * 3 + 1] * beatScale;
        const tz = targetPositions[i * 3 + 2] * beatScale;

        // Current Position LERP
        const cx = rx + (tx - rx) * handClosedAmount;
        const cy = ry + (ty - ry) * handClosedAmount;
        const cz = rz + (tz - rz) * handClosedAmount;

        // Add some noise/wobble
        const noise = Math.sin(time * 2 + i) * 0.05 * (1 - handClosedAmount);
        
        positionsAttribute.setXYZ(i, cx + noise, cy + noise, cz + noise);

        // Interpolate Colors
        // Open: Blue, Closed: Red
        const r = color2.r + (color1.r - color2.r) * handClosedAmount;
        const g = color2.g + (color1.g - color2.g) * handClosedAmount;
        const b = color2.b + (color1.b - color2.b) * handClosedAmount;

        // Make it brighter on beat
        const brightness = 1 + beatTime * 0.5;

        colorsAttribute.setXYZ(i, r * brightness, g * brightness, b * brightness);
    }

    positionsAttribute.needsUpdate = true;
    colorsAttribute.needsUpdate = true;

    // UI Canvas Resizing
    if (canvasElement.width !== videoElement.videoWidth) {
        canvasElement.width = videoElement.videoWidth;
        canvasElement.height = videoElement.videoHeight;
    }

    renderer.render(scene, camera);
}

animate();

// Handle Resize
window.addEventListener('resize', () => {
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
    renderer.setSize(window.innerWidth, window.innerHeight);
});

</script>
</body>
</html>
