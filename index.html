<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Bio-Interactive Particle System</title>
    <style>
        body { margin: 0; overflow: hidden; background: #000; font-family: 'Segoe UI', sans-serif; }
        
        /* Main 3D Canvas */
        #c { width: 100vw; height: 100vh; display: block; }

        /* UI Overlay - Heart Rate (Top Right) */
        #hr-container {
            position: absolute; top: 20px; right: 20px;
            color: #00ff88; background: rgba(0, 20, 10, 0.8);
            padding: 15px; border-radius: 10px; border: 1px solid #00ff88;
            text-align: right; pointer-events: none;
        }
        #bpm-display { font-size: 3rem; font-weight: bold; }
        #bpm-label { font-size: 0.8rem; text-transform: uppercase; letter-spacing: 2px; }

        /* UI Overlay - Webcam (Bottom Right) */
        #webcam-container {
            position: absolute; bottom: 20px; right: 20px;
            width: 240px; height: 180px;
            border-radius: 10px; overflow: hidden;
            border: 2px solid rgba(255, 255, 255, 0.2);
            z-index: 10;
        }
        #input_video {
            width: 100%; height: 100%; object-fit: cover; transform: scaleX(-1);
        }

        /* Status / Instructions */
        #status {
            position: absolute; top: 20px; left: 20px;
            color: rgba(255, 255, 255, 0.7); pointer-events: none;
        }

        /* Hidden Canvas for PPG processing */
        #ppg-canvas { display: none; }
    </style>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
</head>
<body>

    <div id="status">
        <h3>System Ready</h3>
        <p>Gestures: Open Hand (Sphere), Fist (Cube), Point (Torus)</p>
        <p>Two Hands: Move apart to expand size.</p>
    </div>

    <div id="hr-container">
        <div id="bpm-display">--</div>
        <div id="bpm-label">Heart Rate (BPM)</div>
    </div>

    <div id="webcam-container">
        <video id="input_video" autoplay playsinline></video>
    </div>

    <canvas id="ppg-canvas"></canvas>
    
    <canvas id="c"></canvas>

<script>
/**
 * PART 1: THREE.JS SETUP & PARTICLE SYSTEM
 */
const canvas = document.querySelector('#c');
const renderer = new THREE.WebGLRenderer({canvas, antialias: true, alpha: true});
const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
camera.position.z = 30;

const scene = new THREE.Scene();
scene.fog = new THREE.FogExp2(0x000000, 0.02);

// Particle Configuration
const PARTICLE_COUNT = 8000;
const geometry = new THREE.BufferGeometry();
const positions = new Float32Array(PARTICLE_COUNT * 3);
const targetPositions = new Float32Array(PARTICLE_COUNT * 3); // Where particles want to go
const velocities = new Float32Array(PARTICLE_COUNT * 3); // For dissipation physics

// Initialize generic random cloud
for(let i = 0; i < PARTICLE_COUNT * 3; i++) {
    positions[i] = (Math.random() - 0.5) * 50;
    targetPositions[i] = positions[i];
    velocities[i] = 0;
}

geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));

// Material
const textureLoader = new THREE.TextureLoader();
// Generating a simple circle texture programmatically to avoid external asset dependency issues
const circleCanvas = document.createElement('canvas');
circleCanvas.width = 32; circleCanvas.height = 32;
const ctx = circleCanvas.getContext('2d');
ctx.beginPath();
ctx.arc(16, 16, 15, 0, 2 * Math.PI);
ctx.fillStyle = '#ffffff';
ctx.fill();
const sprite = new THREE.CanvasTexture(circleCanvas);

const material = new THREE.PointsMaterial({
    size: 0.3,
    map: sprite,
    color: 0x00ffff,
    transparent: true,
    opacity: 0.8,
    blending: THREE.AdditiveBlending,
    depthWrite: false
});

const particleSystem = new THREE.Points(geometry, material);
scene.add(particleSystem);

// Pre-calculate Shapes
function getSpherePoint(i) {
    const phi = Math.acos(-1 + (2 * i) / PARTICLE_COUNT);
    const theta = Math.sqrt(PARTICLE_COUNT * Math.PI) * phi;
    const r = 10;
    return {
        x: r * Math.cos(theta) * Math.sin(phi),
        y: r * Math.sin(theta) * Math.sin(phi),
        z: r * Math.cos(phi)
    };
}

function getCubePoint(i) {
    const r = 8; 
    // Simple random point inside cube volume for now
    return {
        x: (Math.random() - 0.5) * 2 * r,
        y: (Math.random() - 0.5) * 2 * r,
        z: (Math.random() - 0.5) * 2 * r
    };
}

function getTorusPoint(i) {
    const u = Math.random() * Math.PI * 2;
    const v = Math.random() * Math.PI * 2;
    const R = 8; const r = 3;
    return {
        x: (R + r * Math.cos(v)) * Math.cos(u),
        y: (R + r * Math.cos(v)) * Math.sin(u),
        z: r * Math.sin(v)
    };
}

// Logic Variables
let currentShape = 'sphere'; // sphere, cube, torus, dissipate
let handDetected = false;
let lastHandTime = 0;
let sceneScale = 1;

/**
 * PART 2: MEDIAPIPE HAND TRACKING & GESTURE LOGIC
 */
const videoElement = document.getElementById('input_video');

function onResults(results) {
    const hands = results.multiHandLandmarks;
    
    if (hands && hands.length > 0) {
        handDetected = true;
        lastHandTime = Date.now();
        
        // 1. Detect Hand Span (Scaling)
        if (hands.length === 2) {
            // Calculate distance between wrist of hand 1 and wrist of hand 2
            const dx = hands[0][0].x - hands[1][0].x;
            const dy = hands[0][0].y - hands[1][0].y;
            const dist = Math.sqrt(dx*dx + dy*dy);
            // Map distance (approx 0.1 to 0.8) to scale (0.5 to 2.5)
            const targetScale = Math.max(0.5, Math.min(3.0, dist * 4));
            sceneScale = sceneScale * 0.9 + targetScale * 0.1; // Smooth lerp
        } else {
            // One hand: base scale on "openness" of hand (Tension)
            const wrist = hands[0][0];
            const middleTip = hands[0][12];
            const tension = Math.sqrt(Math.pow(wrist.x - middleTip.x, 2) + Math.pow(wrist.y - middleTip.y, 2));
            sceneScale = sceneScale * 0.9 + (0.5 + tension * 2) * 0.1;
        }

        // 2. Gesture Recognition (Simple Heuristics)
        const lm = hands[0]; // Use primary hand for shape
        
        // Check if fingers are curled (Tip closer to wrist than PIP joint)
        const isFingerCurled = (tipIdx, pipIdx) => {
            const dTip = Math.sqrt(Math.pow(lm[tipIdx].x - lm[0].x, 2) + Math.pow(lm[tipIdx].y - lm[0].y, 2));
            const dPip = Math.sqrt(Math.pow(lm[pipIdx].x - lm[0].x, 2) + Math.pow(lm[pipIdx].y - lm[0].y, 2));
            return dTip < dPip;
        };

        const thumbOpen = !isFingerCurled(4, 2);
        const indexOpen = !isFingerCurled(8, 6);
        const middleOpen = !isFingerCurled(12, 10);
        const ringOpen = !isFingerCurled(16, 14);
        const pinkyOpen = !isFingerCurled(20, 18);

        let fingersOpen = [thumbOpen, indexOpen, middleOpen, ringOpen, pinkyOpen].filter(Boolean).length;

        if (fingersOpen <= 1) {
            currentShape = 'cube'; // Fist
            material.color.setHex(0xff0055); // Red/Pink
        } else if (indexOpen && !middleOpen && !ringOpen && !pinkyOpen) {
            currentShape = 'torus'; // Pointing
            material.color.setHex(0xffff00); // Yellow
        } else {
            currentShape = 'sphere'; // Open Hand
            material.color.setHex(0x00ffff); // Cyan
        }

    } else {
        handDetected = false;
    }
}

const hands = new Hands({locateFile: (file) => {
    return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
}});

hands.setOptions({
    maxNumHands: 2,
    modelComplexity: 1,
    minDetectionConfidence: 0.5,
    minTrackingConfidence: 0.5
});
hands.onResults(onResults);

const cameraUtils = new Camera(videoElement, {
    onFrame: async () => {
        await hands.send({image: videoElement});
        processPPG(); // Run Heart Rate logic on every frame
    },
    width: 640,
    height: 480
});
cameraUtils.start();


/**
 * PART 3: PPG HEART RATE MONITOR (SIMPLIFIED)
 * Logic: Analyze Green channel intensity on the forehead.
 */
const ppgCanvas = document.getElementById('ppg-canvas');
const ppgCtx = ppgCanvas.getContext('2d', {willReadFrequently: true});
const bpmDisplay = document.getElementById('bpm-display');

// Signal processing buffers
const signalBuffer = [];
const BUFFER_SIZE = 150; // approx 5 seconds at 30fps
let lastBPMPulses = [];

function processPPG() {
    if (videoElement.paused || videoElement.ended) return;

    ppgCanvas.width = videoElement.videoWidth;
    ppgCanvas.height = videoElement.videoHeight;
    
    // Draw current video frame to hidden canvas
    ppgCtx.drawImage(videoElement, 0, 0, ppgCanvas.width, ppgCanvas.height);

    // Define ROI (Region of Interest) - Approximate Forehead
    // Assuming user is centered: Top center of the frame
    const roiX = Math.floor(ppgCanvas.width * 0.4);
    const roiY = Math.floor(ppgCanvas.height * 0.1);
    const roiW = Math.floor(ppgCanvas.width * 0.2);
    const roiH = Math.floor(ppgCanvas.height * 0.15);

    // Get pixel data
    const frameData = ppgCtx.getImageData(roiX, roiY, roiW, roiH);
    const data = frameData.data;
    
    let greenSum = 0;
    // Sum green channel
    for (let i = 0; i < data.length; i += 4) {
        greenSum += data[i + 1]; 
    }
    const greenAvg = greenSum / (data.length / 4);

    // Push to buffer
    signalBuffer.push({ t: Date.now(), val: greenAvg });
    if (signalBuffer.length > BUFFER_SIZE) signalBuffer.shift();

    // Calculate BPM every 30 frames
    if (signalBuffer.length === BUFFER_SIZE && Date.now() % 10 === 0) {
        calculateBPM();
    }
}

function calculateBPM() {
    // 1. Detrending (Simple moving average subtraction)
    const values = signalBuffer.map(s => s.val);
    const windowSize = 15;
    const cleanSignal = [];

    for(let i=0; i<values.length; i++) {
        let sum = 0, count = 0;
        for(let j=Math.max(0, i-windowSize); j<Math.min(values.length, i+windowSize); j++) {
            sum += values[j]; count++;
        }
        cleanSignal.push(values[i] - (sum/count));
    }

    // 2. Peak Detection
    let peaks = 0;
    for(let i=1; i<cleanSignal.length-1; i++) {
        // Find local maxima
        if(cleanSignal[i] > cleanSignal[i-1] && cleanSignal[i] > cleanSignal[i+1] && cleanSignal[i] > 0.5) {
            peaks++;
        }
    }

    // 3. Convert to BPM (peaks over the buffer duration)
    const durationSec = (signalBuffer[signalBuffer.length-1].t - signalBuffer[0].t) / 1000;
    let bpm = Math.round((peaks / durationSec) * 60);

    // Clamp to realistic values
    if (bpm > 40 && bpm < 200) {
        lastBPMPulses.push(bpm);
        if(lastBPMPulses.length > 5) lastBPMPulses.shift();
        
        // Smooth display
        const avgBpm = Math.floor(lastBPMPulses.reduce((a,b)=>a+b,0) / lastBPMPulses.length);
        bpmDisplay.innerText = avgBpm;
    }
}


/**
 * PART 4: ANIMATION LOOP
 */
function animate() {
    requestAnimationFrame(animate);

    const positionsArray = geometry.attributes.position.array;
    const time = Date.now() * 0.001;

    // Check dissipation (No hands for 2 seconds)
    let dissipating = (!handDetected && (Date.now() - lastHandTime > 2000));

    for(let i = 0; i < PARTICLE_COUNT; i++) {
        const i3 = i * 3;
        
        // Determine Target
        let target = {x:0, y:0, z:0};
        
        if (dissipating) {
            // Explosion/Falling physics
            velocities[i3 + 1] -= 0.05; // Gravity
            positionsArray[i3] += velocities[i3] + (Math.random()-0.5);
            positionsArray[i3+1] += velocities[i3+1];
            positionsArray[i3+2] += velocities[i3+2] + (Math.random()-0.5);
        } else {
            // Shape Morphing
            if (currentShape === 'sphere') target = getSpherePoint(i);
            else if (currentShape === 'cube') target = getCubePoint(i);
            else if (currentShape === 'torus') target = getTorusPoint(i);

            // Apply Scaling
            target.x *= sceneScale;
            target.y *= sceneScale;
            target.z *= sceneScale;

            // Add subtle noise/breathing
            target.x += Math.sin(time + i) * 0.1;
            target.y += Math.cos(time + i) * 0.1;

            // Lerp Position (move 5% towards target per frame)
            positionsArray[i3] += (target.x - positionsArray[i3]) * 0.05;
            positionsArray[i3+1] += (target.y - positionsArray[i3+1]) * 0.05;
            positionsArray[i3+2] += (target.z - positionsArray[i3+2]) * 0.05;

            // Reset velocity for next dissipation event
            velocities[i3] = (Math.random()-0.5) * 0.5;
            velocities[i3+1] = (Math.random()-0.5) * 0.5;
            velocities[i3+2] = (Math.random()-0.5) * 0.5;
        }
    }

    geometry.attributes.position.needsUpdate = true;
    
    // Slow rotation of the whole system
    particleSystem.rotation.y += 0.002;
    particleSystem.rotation.z += 0.001;

    renderer.render(scene, camera);
}

// Handle Resize
window.addEventListener('resize', () => {
    renderer.setSize(window.innerWidth, window.innerHeight);
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
});

animate();

</script>
</body>
</html>
