<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Bio-Interactive Particle System</title>
    <style>
        body { margin: 0; overflow: hidden; background-color: #050505; font-family: 'Segoe UI', sans-serif; }
        
        /* UI Overlay */
        #ui-layer {
            position: absolute;
            top: 20px;
            left: 20px;
            color: rgba(255, 255, 255, 0.8);
            pointer-events: none;
            z-index: 10;
        }
        h1 { font-weight: 300; margin: 0; letter-spacing: 2px; font-size: 1.5rem; }
        p { font-size: 0.9rem; color: rgba(255,255,255,0.5); }
        
        /* Heart Rate Display */
        #bpm-display {
            position: absolute;
            top: 20px;
            right: 20px;
            text-align: right;
            color: #ff3366;
        }
        #bpm-value { font-size: 3rem; font-weight: 700; }
        #bpm-label { font-size: 0.8rem; text-transform: uppercase; letter-spacing: 1px; color: #fff; }

        /* Webcam Feed */
        #webcam-container {
            position: absolute;
            bottom: 20px;
            right: 20px;
            width: 200px;
            height: 150px;
            border-radius: 12px;
            overflow: hidden;
            border: 1px solid rgba(255,255,255,0.1);
            z-index: 5;
            background: #000;
        }
        video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1); /* Mirror feedback */
        }

        /* Loading Overlay */
        #loader {
            position: fixed;
            top: 0; left: 0; width: 100%; height: 100%;
            background: #000;
            display: flex;
            justify-content: center;
            align-items: center;
            flex-direction: column;
            color: #fff;
            z-index: 100;
            transition: opacity 0.5s;
        }
        .spinner {
            width: 40px; height: 40px;
            border: 4px solid #333;
            border-top: 4px solid #fff;
            border-radius: 50%;
            animation: spin 1s linear infinite;
            margin-bottom: 15px;
        }
        @keyframes spin { 100% { transform: rotate(360deg); } }
        
        /* Legend */
        #legend {
            position: absolute;
            bottom: 20px;
            left: 20px;
            font-size: 0.8rem;
            color: rgba(255,255,255,0.6);
            line-height: 1.6;
        }
        b { color: #fff; }
    </style>
    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
                "@mediapipe/tasks-vision": "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3"
            }
        }
    </script>
</head>
<body>

    <div id="loader">
        <div class="spinner"></div>
        <div>Initializing AI Models...</div>
    </div>

    <div id="ui-layer">
        <h1>BIO-PARTICLES</h1>
        <p>Left Hand: Tension | Right Hand: Shape Selector</p>
    </div>

    <div id="bpm-display">
        <div id="bpm-value">--</div>
        <div id="bpm-label">Heart Rate</div>
    </div>

    <div id="legend">
        <b>Right Hand Gestures:</b><br>
        ‚úä Fist: Heart Mode<br>
        ‚òùÔ∏è 1 Finger: Snake (Spiral)<br>
        ‚úåÔ∏è 2 Fingers: Bird (Wings)<br>
        ü§ü 3 Fingers: Fish (Stream)<br>
        üññ 4 Fingers: Spider (Legs)<br>
        üñêÔ∏è 5 Fingers: Jellyfish (Dome)
    </div>

    <div id="webcam-container">
        <video id="webcam" autoplay playsinline></video>
    </div>

    <canvas id="proc-canvas" style="display:none;"></canvas>

<script type="module">
import * as THREE from 'three';
import { FilesetResolver, FaceLandmarker, HandLandmarker } from '@mediapipe/tasks-vision';

// --- CONFIGURATION ---
const PARTICLE_COUNT = 4000;
const PARTICLE_SIZE = 0.08; // Base size
const EXPANSION_FACTOR = 4; // How much particles spread on open hand

// --- STATE MANAGEMENT ---
const state = {
    heartRate: 70, // Baseline BPM
    targetBPM: 70,
    isHeartMode: false,
    currentShapeIndex: 0, // 0-9
    tension: 0, // 0 (closed) to 1 (open)
    beatPhase: 0,
    lastBeatTime: 0,
    foreheadPoints: [],
    videoElement: document.getElementById('webcam'),
    canvasElement: document.getElementById('proc-canvas'),
    ctx: document.getElementById('proc-canvas').getContext('2d', { willReadFrequently: true })
};

// --- THREE.JS SETUP ---
const scene = new THREE.Scene();
scene.fog = new THREE.FogExp2(0x050505, 0.05);

const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
camera.position.z = 6;

const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
renderer.setSize(window.innerWidth, window.innerHeight);
renderer.setPixelRatio(window.devicePixelRatio);
document.body.appendChild(renderer.domElement);

// --- PARTICLE SYSTEM ---
const geometry = new THREE.BufferGeometry();
const positions = new Float32Array(PARTICLE_COUNT * 3);
const targetPositions = new Float32Array(PARTICLE_COUNT * 3);
const colors = new Float32Array(PARTICLE_COUNT * 3);
const sizes = new Float32Array(PARTICLE_COUNT);

// Initialize random cloud
for (let i = 0; i < PARTICLE_COUNT; i++) {
    positions[i * 3] = (Math.random() - 0.5) * 10;
    positions[i * 3 + 1] = (Math.random() - 0.5) * 10;
    positions[i * 3 + 2] = (Math.random() - 0.5) * 10;
    sizes[i] = Math.random();
}

geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
geometry.setAttribute('color', new THREE.BufferAttribute(colors, 3));
geometry.setAttribute('size', new THREE.BufferAttribute(sizes, 1));

const material = new THREE.PointsMaterial({
    size: PARTICLE_SIZE,
    vertexColors: true,
    blending: THREE.AdditiveBlending,
    depthTest: false,
    transparent: true,
    opacity: 0.8
});

const particles = new THREE.Points(geometry, material);
scene.add(particles);

// --- SHAPE GENERATORS ---
// We generate target positions mathematically
function getShapePoint(index, total, shapeType, time) {
    const p = index / total;
    const phi = Math.acos(-1 + (2 * index) / total);
    const theta = Math.sqrt(total * Math.PI) * phi;
    
    let x, y, z;

    switch(shapeType) {
        case 'HEART': // Heart
            // parametric heart
            const t = p * Math.PI * 2;
            // complex heart formula approximation
            x = 16 * Math.pow(Math.sin(t), 3);
            y = 13 * Math.cos(t) - 5 * Math.cos(2*t) - 2 * Math.cos(3*t) - Math.cos(4*t);
            z = (Math.random() - 0.5) * 4; 
            // Normalize
            x /= 10; y /= 10;
            // Add volume
            const r = 1 - Math.abs(z);
            x *= r; y *= r;
            break;

        case 0: // Sphere (Rest)
            x = 2 * Math.cos(theta) * Math.sin(phi);
            y = 2 * Math.sin(theta) * Math.sin(phi);
            z = 2 * Math.cos(phi);
            break;

        case 1: // Snake (Spiral Helix)
            const coil = p * 10 * Math.PI;
            const flow = time * (state.heartRate/60); 
            x = Math.sin(coil + flow) * 1.5;
            y = (p - 0.5) * 6;
            z = Math.cos(coil + flow) * 1.5;
            break;

        case 2: // Bird (V Shape with flapping)
            const wingX = (p - 0.5) * 6;
            const flapSpeed = time * (state.heartRate/30);
            y = Math.sin(Math.abs(wingX) * 2 + flapSpeed) * 1.5;
            x = wingX;
            z = (Math.random()-0.5);
            break;

        case 3: // Fish (Stream/Oval)
            const angle = p * Math.PI * 2;
            const swim = Math.sin(time * 3 + (p * 10)); // Swimming motion
            x = (p - 0.5) * 6;
            y = Math.sin(angle) * (0.8 + swim * 0.2);
            z = Math.cos(angle) * 0.5;
            break;
        
        case 4: // Spider (Legs)
            const legIndex = index % 8;
            const legProg = Math.floor(index / 8) / (total/8);
            const legAngle = (legIndex / 8) * Math.PI * 2;
            const radius = legProg * 3;
            const lift = Math.sin(time * 4 + legIndex) * 0.5; // Crawl
            x = Math.cos(legAngle) * radius;
            z = Math.sin(legAngle) * radius;
            y = Math.sin(radius * 2) - 1 + lift;
            break;

        case 5: // Jellyfish (Dome + Tentacles)
            if (index < total * 0.3) {
                // Dome
                const dTheta = Math.random() * Math.PI * 2;
                const dPhi = Math.random() * Math.PI * 0.5;
                const r = 1.5;
                x = r * Math.sin(dPhi) * Math.cos(dTheta);
                z = r * Math.sin(dPhi) * Math.sin(dTheta);
                y = r * Math.cos(dPhi) + 1;
            } else {
                // Tentacles
                const tIdx = index % 8;
                const tH = (index / total) * 4;
                const tAngle = (tIdx / 8) * Math.PI * 2;
                const tWave = Math.sin(time * 2 + tH * 5);
                x = Math.cos(tAngle) * 1 + tWave * 0.2;
                z = Math.sin(tAngle) * 1 + tWave * 0.2;
                y = 1 - tH;
            }
            break;

        default: // Random for indices 6-9
            x = (Math.random() - 0.5) * 5;
            y = (Math.random() - 0.5) * 5;
            z = (Math.random() - 0.5) * 5;
    }
    return {x, y, z};
}

// --- MEDIAPIPE SETUP ---
let handLandmarker = undefined;
let faceLandmarker = undefined;

async function createAI() {
    const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
    
    handLandmarker = await HandLandmarker.createFromOptions(vision, {
        baseOptions: { modelAssetPath: `https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task` },
        runningMode: "VIDEO",
        numHands: 2
    });

    faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
        baseOptions: { modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task` },
        runningMode: "VIDEO",
        outputFaceBlendshapes: false,
        numFaces: 1
    });

    // Start Webcam
    navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
        state.videoElement.srcObject = stream;
        state.videoElement.addEventListener("loadeddata", predictWebcam);
        document.getElementById('loader').style.opacity = 0;
        setTimeout(() => document.getElementById('loader').remove(), 500);
    });
}

// --- PPG HEART RATE LOGIC (Simplified Green Channel Analysis) ---
const signalBuffer = [];
const bufferSize = 150; // frames
let lastBeat = 0;

function processFaceForPPG(landmarks) {
    if (!landmarks || landmarks.length === 0) return;
    
    const face = landmarks[0];
    // Forehead indices approx: 10, 338, 297, 332 (Center forehead area)
    // We map these to video coordinates
    const v = state.videoElement;
    const c = state.canvasElement;
    
    // Resize canvas to match video stream if needed
    if (c.width !== v.videoWidth) {
        c.width = v.videoWidth;
        c.height = v.videoHeight;
    }
    
    // Draw current video frame to canvas
    state.ctx.drawImage(v, 0, 0, c.width, c.height);
    
    // Extract a small patch from forehead (Index 151 is approx center forehead)
    const p = face[151]; 
    const x = Math.floor(p.x * c.width);
    const y = Math.floor(p.y * c.height);
    
    // Safety check bounds
    if(x < 10 || y < 10 || x > c.width-10 || y > c.height-10) return;

    // Get 10x10 pixel area average green
    const frameData = state.ctx.getImageData(x-5, y-5, 10, 10).data;
    let avgGreen = 0;
    for(let i=0; i<frameData.length; i+=4) {
        avgGreen += frameData[i+1];
    }
    avgGreen /= (frameData.length/4);

    // Signal Processing
    signalBuffer.push(avgGreen);
    if (signalBuffer.length > bufferSize) signalBuffer.shift();

    // Simple Beat Detection (Peak over moving average)
    if (signalBuffer.length > 30) {
        const localAvg = signalBuffer.reduce((a,b)=>a+b) / signalBuffer.length;
        // Threshold check with rudimentary debounce
        const now = Date.now();
        if (avgGreen > localAvg * 1.01 && (now - lastBeat) > 500) {
            lastBeat = now;
            // Calculate BPM
            const instantBPM = 60000 / (now - state.lastBeatTime);
            state.lastBeatTime = now;
            
            // Smooth BPM
            if (instantBPM > 40 && instantBPM < 160) {
                state.targetBPM = instantBPM;
                state.heartRate += (state.targetBPM - state.heartRate) * 0.1;
            }
            
            // Trigger visual beat
            state.beatPhase = 1.0; 
        }
    }
    
    document.getElementById('bpm-value').innerText = Math.round(state.heartRate);
}


// --- MAIN LOOP ---
let lastTime = -1;
function predictWebcam() {
    let now = performance.now();
    if (lastTime !== -1) {
        // Run detection
        if (handLandmarker) {
            const handResult = handLandmarker.detectForVideo(state.videoElement, now);
            processHands(handResult);
        }
        if (faceLandmarker) {
            const faceResult = faceLandmarker.detectForVideo(state.videoElement, now);
            processFaceForPPG(faceResult.faceLandmarks);
        }
    }
    lastTime = now;
    requestAnimationFrame(predictWebcam);
}

function processHands(result) {
    let tensionHandFound = false;
    let shapeHandFound = false;

    if (result.landmarks.length > 0) {
        // Iterate detected hands
        for (let i = 0; i < result.landmarks.length; i++) {
            const hand = result.landmarks[i];
            const handedness = result.handedness[i][0].categoryName; // "Left" or "Right"
            
            // NOTE: MediaPipe Selfie Mode mirrors things. 
            // "Left" in code usually detects the user's right hand in selfie view if not mirrored properly,
            // but we flipped video with CSS. Let's assume standard logic:
            
            // Calculate finger extension (Is finger tip above PIP joint?)
            // Indices: Thumb(4), Index(8), Middle(12), Ring(16), Pinky(20)
            // MCP joints: 2, 5, 9, 13, 17
            let fingersUp = 0;
            if (hand[4].y < hand[3].y) fingersUp++; // Simple thumb check
            if (hand[8].y < hand[6].y) fingersUp++;
            if (hand[12].y < hand[10].y) fingersUp++;
            if (hand[16].y < hand[14].y) fingersUp++;
            if (hand[20].y < hand[18].y) fingersUp++;

            // Distance between Index Tip and Thumb Tip (Pinch/Tension)
            const dx = hand[8].x - hand[4].x;
            const dy = hand[8].y - hand[4].y;
            const dist = Math.sqrt(dx*dx + dy*dy);

            if (handedness === "Right") {
                // RIGHT HAND LOGIC: Shape Selector
                shapeHandFound = true;
                if (fingersUp === 0) {
                    state.isHeartMode = true;
                } else {
                    state.isHeartMode = false;
                    state.currentShapeIndex = fingersUp; // 1 to 5
                }
            } 
            else {
                // LEFT HAND LOGIC: Tension/Scaling
                tensionHandFound = true;
                // Map distance to tension: High distance = Open (1), Low = Closed (0)
                // Average pinch dist is roughly 0.02 to 0.2
                let t = (dist - 0.02) * 5; 
                if (t < 0) t = 0;
                if (t > 1) t = 1;
                state.tension = t;
            }
        }
    }

    // Fallback if hands lost
    if (!tensionHandFound) state.tension += (1 - state.tension) * 0.05; // Default to open
}

// --- ANIMATION LOOP ---
const clock = new THREE.Clock();

function animate() {
    requestAnimationFrame(animate);

    const time = clock.getElapsedTime();
    const positionsAttr = geometry.attributes.position;
    const colorAttr = geometry.attributes.color;

    // Pulse Logic
    if (state.beatPhase > 0) {
        state.beatPhase -= 0.05; // Decay beat
    }
    const pulse = 1 + (state.beatPhase * 0.2); // 20% scale bump on beat

    // Update Particles
    for (let i = 0; i < PARTICLE_COUNT; i++) {
        // Determine Target Shape
        let target;
        if (state.isHeartMode) {
            target = getShapePoint(i, PARTICLE_COUNT, 'HEART', time);
        } else {
            target = getShapePoint(i, PARTICLE_COUNT, state.currentShapeIndex, time);
        }

        // Apply Tension (Expansion/Condensation)
        // Tension 1 = Normal Scale. Tension 0 = Condensed (tiny) or Exploded?
        // Requirement: "One hand's tension used to condense". 
        // So Low Tension (Hand closed) = Condensed. High Tension (Hand Open) = Expanded.
        // Let's modify: Left Hand Open (High Dist) = Expanded Cloud. Left Hand Closed = Tight Shape.
        
        const tensionMod = 0.2 + (state.tension * 2.0); // range 0.2 to 2.2 scale

        const tx = target.x * tensionMod * pulse;
        const ty = target.y * tensionMod * pulse;
        const tz = target.z * tensionMod * pulse;

        // Lerp current position to target
        const vx = positionsAttr.getX(i);
        const vy = positionsAttr.getY(i);
        const vz = positionsAttr.getZ(i);

        // Speed based on HeartRate (faster heart = faster morph)
        const speed = 0.05 + (state.heartRate / 2000);

        positionsAttr.setXYZ(
            i,
            vx + (tx - vx) * speed,
            vy + (ty - vy) * speed,
            vz + (tz - vz) * speed
        );

        // Coloring
        const col = new THREE.Color();
        if (state.isHeartMode) {
            col.setHSL(0.95, 1.0, 0.5); // Red
        } else {
            // Color based on shape index
            const hue = (state.currentShapeIndex * 0.1) % 1;
            col.setHSL(hue, 0.7, 0.5);
        }
        colorAttr.setXYZ(i, col.r, col.g, col.b);
    }

    positionsAttr.needsUpdate = true;
    colorAttr.needsUpdate = true;

    // Gentle rotation
    scene.rotation.y = time * 0.1;

    renderer.render(scene, camera);
}

// Start
createAI();
animate();

// Handle Resize
window.addEventListener('resize', () => {
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
    renderer.setSize(window.innerWidth, window.innerHeight);
});

</script>
</body>
</html>
